# GPT Model Training

## Описание проекта

Этот проект представляет собой базовую архитектуру для обучения модели GPT (Generative Pre-trained Transformer). Проект включает несколько файлов, таких как конфигурационный файл config.json, исходный код модели, скрипт обучения и файл с входными данными. Конфигурационный файл задаёт параметры модели, которые можно настроить для оптимизации производительности и точности.


### Файлы

- **config/config.json**: Хранит настройки модели.
- **input.txt**: Содержит текстовые данные, используемые для обучения модели.
- **model.py**: Содержит реализацию архитектуры GPT.
- **train.ipynb**: Jupyter Notebook, который используется для запуска и мониторинга процесса обучения.

---

## Описание параметров конфигурации

Файл config.json определяет параметры модели. Ниже приводится описание каждого параметра:

| Параметр               | Тип    | Значение по умолчанию | Описание                                                                 |
|------------------------|--------|-----------------------|--------------------------------------------------------------------------|
| heads               | int    | 16                    | Количество attention-глав в модели. Увеличение может повысить мощность модели. |
| embedding_size      | int    | 512                   | Размер векторного представления слов. Определяет, как слова кодируются в числовой вид. |
| attention_dropout   | float  | 0.1                   | Уровень dropout для механизма self-attention. Уменьшает переобучение.   |
| dropout             | float  | 0.1                   | Общий уровень dropout для модели. Помогает избежать переобучения.      |
| dict_size           | int    | 50259                 | Размер словаря. Определяет количество уникальных токенов.               |
| hidden_layer_size   | int    | 2560                  | Размер скрытого слоя внутри feed-forward блока.                         |
| N_blocks            | int    | 12                    | Количество блоков (слоёв) Transformer. Определяет глубину модели.       |

---
